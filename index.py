from openai import OpenAI
from streamlit_option_menu import option_menu
import streamlit as st
import json
import base64


with open('main/prompt.json', 'r', encoding='utf-8') as f:
    prompt = json.load(f)

# Hide Footer(Made with Streamlit) & Main Menu
hide_st_style = '''
    <style>
        #MainMenu {visibility : hidden;}
        footer {visibility : hidden;}
    </style>
    '''
st.markdown(hide_st_style, unsafe_allow_html = True)

# Nav Bar Setting
with st.sidebar:
    selected = option_menu(
        menu_title = "Menu",
        menu_icon = "menu-button-fill",
        options = ["Record", "Upload", "Transcribe", "Summary", "Q&A"],
        icons = ["mic", "upload", "book", "blockquote-left", "chat-right-dots"],
        #orientation = "horizontal",
        default_index = 1,
    )

# Variables
API_Key = st.secrets["openai_key"] #API Key from OpenAI (Whisper)
client = OpenAI(api_key=API_Key) # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯

# Session State
if 'transcribe_response' not in st.session_state:
    st.session_state['transcribe_response'] = None
if 'summary_response' not in st.session_state:
    st.session_state['summary_response'] = None

# Function
def transcribe_audio():
    if media_file is not None:
        transcribe_response = client.audio.transcriptions.create(
            model=model_id,
            file=media_file,
            response_format='srt'  # text, json, srt, vtt
        )
        return transcribe_response

def summarize_audio(tr_response):
    if media_file is not None:
        summary_response = client.chat.completions.create(
            model="gpt-4",
            messages=prompt,
            temperature=0.5
        )
        return summary_response

# Record Page
if selected == "Record":
    st.title('Record')
    
    st.set_page_config(page_title="èªéŸ³éŒ„éŸ³å™¨", layout="centered")

    st.title("ğŸ¤ å³æ™‚éŒ„éŸ³ç³»çµ±")
    st.markdown("ä½¿ç”¨ä¸‹æ–¹éŒ„éŸ³æŒ‰éˆ•é–‹å§‹éŒ„éŸ³ï¼Œå®Œæˆå¾Œå¯ä¸‹è¼‰éŸ³è¨Šæª”ã€‚")

    # ä½¿ç”¨ st.audio_input å…ƒä»¶
    audio_bytes = st.audio_input("è«‹é»æ“Šé–‹å§‹éŒ„éŸ³", key="audio_recorder")

    if audio_bytes is not None:
        # é¡¯ç¤ºéŸ³è¨Šæ’­æ”¾å™¨
        st.audio(audio_bytes, format="audio/wav")

        # ä¸‹è¼‰é€£çµ
        b64 = base64.b64encode(audio_bytes).decode()
        href = f'<a href="data:audio/wav;base64,{b64}" download="recording.wav">ğŸ“¥ é»æ­¤ä¸‹è¼‰éŒ„éŸ³æª”</a>'
        st.markdown(href, unsafe_allow_html=True)
    else:
        st.info("è«‹é»é¸éŒ„éŸ³æŒ‰éˆ•ä¾†éŒ„è£½èªéŸ³ã€‚")

# Upload Page
if selected == "Upload":
    st.title('Upload')
    
    model_id = 'whisper-1' 
    
    media_file = st.file_uploader('Upload Audio', type = ('wav', 'mp3', 'mp4'))
    
    if media_file is not None:  # Check if a file has been uploaded
        if st.button("Transcribe Audio"):
            transcribe_response = transcribe_audio()
            st.write("Transcription Completed!")
            st.session_state['transcribe_response'] = transcribe_response
            summary_response = summarize_audio(transcribe_response)
            st.write("Summarizing Completed!")
            st.session_state['summary_response'] = summary_response['choices'][0]['message']['content']

# Transcribe Page
if selected == "Transcribe":
    st.title('Transcribe')
    if st.session_state['transcribe_response'] == None:
        st.write("Please Upload & Transcribe Audio First!")
    else:
        st.write(st.session_state['transcribe_response'])

# Summary Page
if selected == "Summary":
    st.title('Summary')
    if st.session_state['summary_response'] == None:
        st.write("Please Upload & Transcribe Audio First!")
    else:
        st.write(st.session_state['summary_response'])

# Q&A Page
if selected == "Q&A":
    if st.session_state['transcribe_response'] == None:
        st.write("Please Upload & Transcribe Audio First!")
    else:
        preset_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "assistant", "content": "Please upload your transcription"},
            {"role": "user", "content": st.session_state['transcribe_response']},
            {"role": "assistant", "content": "é‚£éº¼æ ¹æ“šæ‚¨çš„ç´€éŒ„ï¼Œæ‚¨æœ‰ä»€éº¼æƒ³æå•çš„å—ï¼Ÿ?"}
        ]
        
        if "messages" not in st.session_state:
            st.session_state.messages = preset_messages
    
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        if prompt := st.chat_input("What do you want to know?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.markdown(prompt)
                
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                for response in client.chat.completions.create(
                    model = "gpt-3.5-turbo-1106",
                    messages = [{"role": m["role"], "content": m["content"]}
                              for m in st.session_state.messages], stream=True):
                                  
                    full_response += response.choices[0].delta.get("content", "")
                    message_placeholder.markdown(full_response + "â–Œ")
                                  
                message_placeholder.markdown(full_response)
                
            st.session_state.messages.append({"role": "assistant", "content": full_response})
